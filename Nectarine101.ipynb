{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nectarine101.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLHnvHbLCESYDSC2rXGhrE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YunusKhan/NectarineDemo/blob/master/Nectarine101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0lpz_F0Odyl",
        "colab_type": "code",
        "outputId": "6e1e1da5-1860-45c3-bcc4-005fb6e106a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "print (\" \\\\\\\n",
        "Steps Taken \\n \\\\\\\n",
        "1. Tried 2 approaches - Statistical  (file named 101) and Deep Learning ( file names 102_DL) \\n \\\\\\\n",
        "2. Done some data clean up , kept only right wrist position, and actions 1-5  \\n \\\\\\\n",
        "3. Removed column which has position 2 as it was dead weight and did not carry significance  \\n \\\\\\\n",
        " \\n \\\\\\\n",
        "Linear Regression - very low accuracy of 16  \\n \\\\\\\n",
        "LogisticRegression - even lower accuracy  \\n \\\\\\\n",
        "Decision Tree - 99.6 accuracy  \\n \\\\\\\n",
        "RandomForestRegressor - 99.4 accuracy   \\n \\\\\\\n",
        " \\n \\\\\\\n",
        "Deep Learning  \\n \\\\\\\n",
        "Tried a Simple Dense Model - low accuracy of 15% with 20 epochs \\n \\\\\\\n",
        "Tried a simple Conv1D in Keras - varying accuracy of 25 to 65 % \\n \\\\\\\n",
        "Tried a more complex Conv1d Keras with more layers , regularization, different loss function, different optimizers and activation functions, got better accuracy \\n \\\\\\\n",
        "\\n \\\\\\\n",
        "\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \\Steps Taken \n",
            " \\1. Tried 2 approaches - Statistical  (file named 101) and Deep Learning ( file names 102_DL) \n",
            " \\2. Done some data clean up , kept only right wrist position, and actions 1-5  \n",
            " \\3. Removed column which has position 2 as it was dead weight and did not carry significance  \n",
            " \\ \n",
            " \\Linear Regression - very low accuracy of 16  \n",
            " \\LogisticRegression - even lower accuracy  \n",
            " \\Decision Tree - 99.6 accuracy  \n",
            " \\RandomForestRegressor - 99.4 accuracy   \n",
            " \\ \n",
            " \\Deep Learning  \n",
            " \\Tried a Simple Dense Model - low accuracy of 15% with 20 epochs \n",
            " \\Tried a simple Conv1D in Keras - varying accuracy of 25 to 65 % \n",
            " \\Tried a more complex Conv1d Keras with more layers , regularization, different loss function, different optimizers and activation functions, got better accuracy \n",
            " \\\n",
            " \\\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXNG3jX5f6Rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, ElasticNet\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNpf9uV4gO-Z",
        "colab_type": "code",
        "outputId": "8fc71a79-3b63-47fd-caf5-cda218c32963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulQh9EsViIzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lframe = []\n",
        "path = \"/content/drive/My Drive/FORTH_TRACE_DATASET-master/*/*.csv\"\n",
        "for f in glob.glob(path):\n",
        "    lframe.append(pd.read_csv(f, header=None))\n",
        "df = pd.concat(lframe, ignore_index=False, sort=False, axis=0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBhoEPeukK4S",
        "colab_type": "code",
        "outputId": "c8c51c58-f409-40c5-b0bd-a9ce662da71f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "df = df[ df[0] == 2]  # dropping all other positions based data other than right wrist \n",
        "df = df[ df[11] <= 5] # dropping all other activites other than 1-5 \n",
        "\n",
        "del df[0] # removing the first column because it is only right wrist and is dead weight \n",
        "\n",
        "X_scaled = preprocessing.scale(df[10].values)  # normalising the data on  time stamp as it is very varied and fluctuating so keeping it between -1 & 1\n",
        "# may move it to 0 to 1 or some other thing later, right or some other scaling \n",
        "df[10] = X_scaled\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       1       2       3         4   ...       8        9         10  11\n",
            "0  2.3082  9.5491  1.9084  0.223360  ...  0.91667  0.96711 -1.596097   1\n",
            "1  2.3080  9.5608  1.8841 -0.026525  ...  0.91865  0.96930 -1.596033   1\n",
            "2  2.3321  9.5854  1.8829 -0.331100  ...  0.92460  0.96930 -1.595969   1\n",
            "3  2.2957  9.5724  1.8602 -0.281390  ...  0.90873  0.97368 -1.595905   1\n",
            "4  2.2717  9.5846  1.8727 -0.418700  ...  0.94444  0.97588 -1.595841   1\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAXQh99fk1u5",
        "colab_type": "code",
        "outputId": "0ca13fb1-491d-4b5d-f150-9a4a97289d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "sns.distplot(df[11], bins=20, kde=False, rug=True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkpq7w_4mbXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df.iloc[:,:-1]\n",
        "y = df.iloc[:,10:]\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGa9Jm0UnRaY",
        "colab_type": "code",
        "outputId": "2ad444f9-bf43-4904-eb96-8a1d246cb3a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "print ( x_train, x_test, y_train, y_test )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           1        2       3          4   ...        7        8        9         10\n",
            "40145 -0.5271  13.9880  3.9168  19.425000  ... -0.333330  1.03770  0.51974  1.323595\n",
            "6370   3.8640   6.0422  6.8837   0.078626  ...  0.035197  0.10317  1.73030 -1.187942\n",
            "2066   3.0897   3.1248  8.9653   0.123110  ...  0.147000 -0.25000  1.56360 -1.120863\n",
            "25149  1.8781   9.1614  3.4713   0.229490  ...  0.202900  0.63690  1.31360  0.020138\n",
            "35316  2.5164   9.4602  2.2413  -1.346600  ...  0.223600  0.91865  0.51754  1.131429\n",
            "...       ...      ...     ...        ...  ...       ...      ...      ...       ...\n",
            "52031  2.1171   9.0379  3.2738  -0.231410  ...  0.339540  0.88294  0.67544  1.764259\n",
            "31394  4.7219   9.3733  4.7191  46.725000  ... -0.569360  0.78373  1.30040  0.423138\n",
            "14703  3.9217   2.7321  9.0325   0.255490  ... -0.175980 -0.16865  1.80480 -0.646610\n",
            "6356  -4.9675  -3.2298  8.0690   0.275880  ... -0.612840  0.56746  1.06140 -1.182552\n",
            "1831   2.2136   9.2953  3.2899   0.636880  ...  0.414080  0.80357  1.52410 -1.477992\n",
            "\n",
            "[484241 rows x 10 columns]             1        2        3   ...        8        9         10\n",
            "33354  2.19380   8.9868  2.51350  ...  1.049600  0.48026  0.993787\n",
            "15173  2.90830   9.3431  1.67770  ...  0.755950  1.14910 -0.446622\n",
            "30423  1.45050  13.8390  7.70380  ...  1.174600  0.26535  0.417058\n",
            "38784  4.00020   8.6252  2.43040  ...  0.976190  0.48904  1.099483\n",
            "5087   0.49482   2.2848  9.72260  ... -0.333330  1.61840 -1.269919\n",
            "...        ...      ...      ...  ...       ...      ...       ...\n",
            "24869  2.37150   7.8115  3.41120  ...  0.339290  1.05040  0.183645\n",
            "3262   4.98810   1.4993  8.44690  ... -0.382940  1.44080 -1.382691\n",
            "2204   3.76960   5.9476  7.08120  ...  0.085317  1.74120 -1.455361\n",
            "12927  6.87190   5.0519  5.25910  ...  0.107140  1.61180 -0.766044\n",
            "41585  2.05560   8.4501  0.74523  ...  1.069400  1.11180  1.072599\n",
            "\n",
            "[121061 rows x 10 columns]        11\n",
            "40145   4\n",
            "6370    2\n",
            "2066    2\n",
            "25149   1\n",
            "35316   4\n",
            "...    ..\n",
            "52031   1\n",
            "31394   5\n",
            "14703   3\n",
            "6356    2\n",
            "1831    1\n",
            "\n",
            "[484241 rows x 1 columns]        11\n",
            "33354   4\n",
            "15173   1\n",
            "30423   5\n",
            "38784   4\n",
            "5087    2\n",
            "...    ..\n",
            "24869   5\n",
            "3262    2\n",
            "2204    2\n",
            "12927   3\n",
            "41585   4\n",
            "\n",
            "[121061 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c1tNs05naF6",
        "colab_type": "code",
        "outputId": "b2c65c8a-ce58-47c4-eebb-533f024f95d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(x_train, y_train)\n",
        "linreg_predicted = linreg.predict(x_test)\n",
        "\n",
        "print ('LinearRegression Mean Absolute Error ...', metrics.mean_absolute_error(y_test, linreg_predicted))\n",
        "print ('LinearRegression Mean Squared Error ... ', metrics.mean_squared_error(y_test, linreg_predicted))\n",
        "print ('LinearRegression Root Mean Squared Error ...', np.sqrt(metrics.mean_squared_error(y_test, linreg_predicted)))\n",
        "print (\"LinearRegression Score ... \", linreg.score(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearRegression Mean Absolute Error ... 1.1544945324683602\n",
            "LinearRegression Mean Squared Error ...  1.96055795740219\n",
            "LinearRegression Root Mean Squared Error ... 1.4001992563211103\n",
            "LinearRegression Score ...  0.16497636848980812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWK7IrL4oVcP",
        "colab_type": "code",
        "outputId": "2597324f-c565-4de9-bac9-4a0ffd91eb2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"getting really bad stats so will try to move to a neural network for now and then switch back to statistical learning when I have  time\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "getting really bad stats so will try to move to a neural network for now and then switch back to statistical learning when I have  time\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNYsHrXSFG5L",
        "colab_type": "code",
        "outputId": "14c5dac3-7880-4d35-9d00-02d3bb132f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
        "\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(x_train, y_train)\n",
        "logreg_predicted = linreg.predict(x_test)\n",
        "print('LinearRegression Mean Absolute Error:', metrics.mean_absolute_error(y_test, logreg_predicted))\n",
        "print('LinearRegression Mean Squared Error:', metrics.mean_squared_error(y_test, logreg_predicted))\n",
        "print('LinearRegression Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, logreg_predicted)))\n",
        "print(\"LinearRegression Score ... \", linreg.score(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LinearRegression Mean Absolute Error: 1.2446077977038408\n",
            "LinearRegression Mean Squared Error: 2.7475419842468316\n",
            "LinearRegression Root Mean Squared Error: 1.6575711098613028\n",
            "LinearRegression Score ...  -0.16812808950470082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuEmpF2apliK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ee179cd0-0667-4987-ef14-c811718886dc"
      },
      "source": [
        "param_grid = {'alpha': np.logspace(-3, -1, 25), 'l1_ratio':[0.00001, 0.0001, .001, .01, .1, .9, .98, 1]}\n",
        "grid = GridSearchCV(ElasticNet(normalize=True), param_grid, cv=10)\n",
        "grid.fit(x_train, y_train)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
        "print(\"Best parameters: \", grid.best_params_)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.00\n",
            "Best parameters:  {'alpha': 0.001, 'l1_ratio': 1e-05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1_ZOKFzqZH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "fd923bd0-1185-4821-8a3e-1f3498487a25"
      },
      "source": [
        "criterion = ['gini', 'entropy']\n",
        "max_depth = [4,6,8,12]\n",
        "parameters = {'criterion': ['gini', 'entropy'], 'max_depth':[4,6,8,12]}\n",
        "#parameters = dict(decisiontree__criterion=criterion, decisiontree__max_depth=max_depth)\n",
        "gs_df = GridSearchCV(DecisionTreeClassifier, parameters)\n",
        "gs_df_fit = gs_df.fit(x_train, y_train)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e0301c144300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#parameters = dict(decisiontree__criterion=criterion, decisiontree__max_depth=max_depth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgs_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgs_df_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best Criterion:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decisiontree__criterion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         parallel = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     65\u001b[0m                             \u001b[0;34m\"it does not seem to be a scikit-learn estimator \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                             \u001b[0;34m\"as it does not implement a 'get_params' methods.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                             % (repr(estimator), type(estimator)))\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot clone object '<class 'sklearn.tree._classes.DecisionTreeClassifier'>' (type <class 'abc.ABCMeta'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceZ27Xi7IB6Z",
        "colab_type": "code",
        "outputId": "7570690f-34f6-4094-ac14-7c79dbdee4b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tree = DecisionTreeClassifier()\n",
        "fit = tree.fit(x_train, y_train)\n",
        "decisiontree_pred = tree.predict(x_test)\n",
        "print(\"Decision Tree Plain Accuracy:\",metrics.accuracy_score(y_test, decisiontree_pred))\n",
        "print(\"Decision Tree Score ... \", tree.score(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree Plain Accuracy: 0.9960791008364952\n",
            "Decision Tree Score ...  0.9960791008364952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EelHVjAjJOVN",
        "colab_type": "code",
        "outputId": "b083df28-3811-463b-a993-ebd6d63f0fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "regr_rf = RandomForestRegressor(n_estimators=50, max_depth=100, random_state=2)\n",
        "regr_rf.fit(x_train, y_train)\n",
        "y_rf = regr_rf.predict(x_test)\n",
        "print(\"RandomForestRegressor Score ... \", regr_rf.score(x_test, y_test))\n",
        "print(\"RandomForestRegressor Accuracy:\",metrics.accuracy_score(y_test, y_rf.round()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestRegressor Score ...  0.9940650018144258\n",
            "RandomForestRegressor Accuracy: 0.9923123943367237\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}